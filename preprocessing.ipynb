{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re,string\n",
    "from textacy import preprocessing\n",
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "from textblob import Word\n",
    "from textblob import TextBlob "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_translated_0_to_40000 = pd.read_csv('processed_data/train_translated_0_to_40000.csv')\n",
    "train_translated_40000_to_80000 = pd.read_csv('processed_data/train_translated_40000_to_80000.csv')\n",
    "train_translated_80000_to_120000 = pd.read_csv('processed_data/train_translated_80000_to_120000.csv')\n",
    "train_translated_120000_to_end = pd.read_csv('processed_data/train_translated_120000_to_end.csv')\n",
    "\n",
    "test = pd.read_csv('processed_data/test_translated.csv')\n",
    "test_y = pd.read_csv(\"original_data/test_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([train_translated_0_to_40000, train_translated_40000_to_80000,\n",
    "        train_translated_80000_to_120000, train_translated_120000_to_end], ignore_index=True, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels for the test data; value of -1 indicates it was not used for scoring\n",
    "#we reomve those rows with no actual labels\n",
    "test_y = test_y.loc[test_y['toxic'] != -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"How could I post before the block expires?  The funny thing is, you think I'm being uncivil!\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['comment_text'][30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "repl = {\n",
    "    \"&lt;3\": \" good \",\n",
    "    \"yay!\": \" good \",\n",
    "    \"yay\": \" good \",\n",
    "    \"yaay\": \" good \",\n",
    "    \"yaaay\": \" good \",\n",
    "    \"yaaaay\": \" good \",\n",
    "    \"yaaaaay\": \" good \",\n",
    "    \"&lt;3\": \" heart \",\n",
    "    \":d\": \" smile \",\n",
    "    \":p\": \" smile \",\n",
    "    \":dd\": \" smile \",\n",
    "    \"8)\": \" smile \",\n",
    "    \":-)\": \" smile \",\n",
    "    \":)\": \" smile \",\n",
    "    \";)\": \" smile \",\n",
    "    \"(-:\": \" smile \",\n",
    "    \"(:\": \" smile \",\n",
    "    \":/\": \" worry \",\n",
    "    \":&gt;\": \" angry \",\n",
    "    \":')\": \" sad \",\n",
    "    \":-(\": \" sad \",\n",
    "    \":(\": \" sad \",\n",
    "    \":s\": \" sad \",\n",
    "    \":-s\": \" sad \",\n",
    "    r\"\\br\\b\": \"are\",\n",
    "    r\"\\bu\\b\": \"you\",\n",
    "    r\"\\bhaha\\b\": \"ha\",\n",
    "    r\"\\bhahaha\\b\": \"ha\",\n",
    "    r\"\\bdon't\\b\": \"do not\",\n",
    "    r\"\\bdoesn't\\b\": \"does not\",\n",
    "    r\"\\bdidn't\\b\": \"did not\",\n",
    "    r\"\\bhasn't\\b\": \"has not\",\n",
    "    r\"\\bhaven't\\b\": \"have not\",\n",
    "    r\"\\bhadn't\\b\": \"had not\",\n",
    "    r\"\\bwon't\\b\": \"will not\",\n",
    "    r\"\\bwouldn't\\b\": \"would not\",\n",
    "    r\"\\bcan't\\b\": \"can not\",\n",
    "    r\"\\bcannot\\b\": \"can not\",\n",
    "    r\"\\bi'm\\b\": \"i am\",\n",
    "    \"m\": \"am\",\n",
    "    \"r\": \"are\",\n",
    "    \"u\": \"you\",\n",
    "    \"haha\": \"ha\",\n",
    "    \"hahaha\": \"ha\",\n",
    "    \"don't\": \"do not\",\n",
    "    \"doesn't\": \"does not\",\n",
    "    \"didn't\": \"did not\",\n",
    "    \"hasn't\": \"has not\",\n",
    "    \"haven't\": \"have not\",\n",
    "    \"hadn't\": \"had not\",\n",
    "    \"won't\": \"will not\",\n",
    "    \"wouldn't\": \"would not\",\n",
    "    \"can't\": \"can not\",\n",
    "    \"cannot\": \"can not\",\n",
    "    \"i'm\": \"i am\",\n",
    "    \"m\": \"am\",\n",
    "    \"i'll\" : \"i will\",\n",
    "    \"its\" : \"it is\",\n",
    "    \"it's\" : \"it is\",\n",
    "    \"'s\" : \" is\",\n",
    "    \"that's\" : \"that is\",\n",
    "    \"weren't\" : \"were not\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = [i for i in repl.keys()]\n",
    "\n",
    "new_train_data = []\n",
    "new_test_data = []\n",
    "ltr = train[\"comment_text\"].tolist()\n",
    "lte = test[\"comment_text\"].tolist()\n",
    "for i in ltr:\n",
    "    arr = str(i).split()\n",
    "    xx = \"\"\n",
    "    for j in arr:\n",
    "        j = str(j).lower()\n",
    "        if j[:4] == 'http' or j[:3] == 'www':\n",
    "            continue\n",
    "        if j in keys:\n",
    "            # print(\"inn\")\n",
    "            j = repl[j]\n",
    "        xx += j + \" \"\n",
    "    new_train_data.append(xx)\n",
    "for i in lte:\n",
    "    arr = str(i).split()\n",
    "    xx = \"\"\n",
    "    for j in arr:\n",
    "        j = str(j).lower()\n",
    "        if j[:4] == 'http' or j[:3] == 'www':\n",
    "            continue\n",
    "        if j in keys:\n",
    "            # print(\"inn\")\n",
    "            j = repl[j]\n",
    "        xx += j + \" \"\n",
    "    new_test_data.append(xx)\n",
    "train[\"comment_text\"] = new_train_data\n",
    "test[\"comment_text\"] = new_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(text):\n",
    "    \n",
    "    #replace eamils \n",
    "    text = preprocessing.replace.replace_emails(text, replace_with='EMAIL')\n",
    "    #replace URL\n",
    "    text = preprocessing.replace.replace_urls(text, replace_with= 'URL')\n",
    "    #replace hashtags\n",
    "    text = preprocessing.replace.replace_hashtags(text, replace_with= 'TAG')\n",
    "    \n",
    "    #replace numnber and some characters\n",
    "    text = text.replace('&', 'and')\n",
    "    text = text.replace('@', 'at')\n",
    "    text = text.replace('=', '')\n",
    "    #remove numbers\n",
    "    text = re.sub(r\"[^a-z ]\", \" \", text)\n",
    "    # Replace \\\\n\n",
    "    text = re.sub('\\\\n',' ',text)\n",
    "    #remove punctuation \n",
    "    text = preprocessing.remove.remove_punctuation(text)\n",
    "    \n",
    "    text = re.sub(r\"\\b\\w{1,3}\\b\", \" \",text)\n",
    "    #normalize whitespace\n",
    "    text = re.sub( '\\s+', ' ', text)\n",
    "    \n",
    "    #remove stopwords\n",
    "    stop_words = set(stopwords.words('english')) \n",
    "  \n",
    "    word_tokens = word_tokenize(text) \n",
    "\n",
    "    filtered_sentence = [w for w in word_tokens if not w in stop_words] \n",
    "    filtered_sentence = [] \n",
    "    for w in word_tokens: \n",
    "        if w not in stop_words: \n",
    "            #normalize repeatingchars\n",
    "            w = re.sub(r'(.)\\1+', r'\\1\\1', w)\n",
    "            filtered_sentence.append(w)\n",
    "    text = ' '.join([w for w in filtered_sentence])\n",
    "    return(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_commentTrain = []\n",
    "new_commentTest = []\n",
    "for i in train['comment_text']:\n",
    "    new_commentTrain.append(process_text(i))\n",
    "    \n",
    "for j in test['comment_text']:\n",
    "    new_commentTest.append(process_text(j))\n",
    "\n",
    "train['comment_text'] = new_commentTrain\n",
    "test['comment_text'] = new_commentTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('processed_data/train_translated_cleaned.csv',index=None)\n",
    "test.to_csv('processed_data/test_translated_cleaned.csv',index=None)\n",
    "test_y.to_csv('processed_data/test_labels_cleaned.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
